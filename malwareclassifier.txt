from sklearn import datasets
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from matplotlib.colors import ListedColormap
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score, f1_score
from sklearn.metrics import classification_report
from sklearn.metrics import precision_recall_curve, roc_curve, roc_auc_score
import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn import decomposition
import seaborn as sns
#from sklearn.preprocessing import Imputer
from sklearn.impute import SimpleImputer
import os
from sklearn.ensemble import VotingClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC       
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn import model_selection
from imblearn.under_sampling import NeighbourhoodCleaningRule
from imblearn.under_sampling import OneSidedSelection
from imblearn.under_sampling import EditedNearestNeighbours
from imblearn.under_sampling import CondensedNearestNeighbour
from imblearn.under_sampling import TomekLinks
from collections import Counter
from xgboost import XGBClassifier
from numpy import where
from matplotlib import pyplot
from time import time

chunks = pd.read_csv('database.txt', chunksize=50000,low_memory=False)
df = pd.concat(chunks)

X = df.loc[:,'ACCESS_SUM':'ICONS'].values
y = df.loc[:,'APPLICATION_TYPE'].values

# TP is the number of truly malicious samples from those predicted as malware
# FP is the number of samples that are predicted to be malware that are not truly malicious
# FN is the number of samples that are predicted to be benign that are not truly benign
# TN is the number of truly benign samples from those predicted as benign

def print_stats_percentage_train_test(algorithm_name, y_test, y_pred):

     print("------------------------------------------------------")
     print("------------------------------------------------------")
     print ("algorithm is:", algorithm_name)
     print('accuracy_score %.3f' % accuracy_score(y_test,   y_pred) ) # (TP+TN)/(TP+TN+FP+FN)
     confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)
     print ("confusion matrix")
     print(confmat)
     print (pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True))
     print('Precision: %.3f' % precision_score(y_true=y_test,y_pred=y_pred))  # TP/(TP+FP)
     print('Recall: %.3f' % recall_score(y_true=y_test,y_pred=y_pred))  # TP/(TP+FN)
     print('F1-measure: %.3f' % f1_score(y_true=y_test,y_pred=y_pred )) # recall*precision/recall+precision
     
from sklearn.metrics import auc
def knn_rc(X_train_std, y_train, X_test_std, y_test):
    knn = KNeighborsClassifier(n_neighbors=8, p=5, metric='minkowski')  ## 8 ve 5 ilk hali
    knn.fit(X_train_std, y_train)
    y_pred = knn.predict(X_test_std)
    print_stats_percentage_train_test(knn, y_test, y_pred)
    
def logistic_regression_rc(X_train_std, y_train, X_test_std, y_test):
    lr=LogisticRegression(solver='lbfgs', max_iter=1000)
    lr.fit(X_train_std, y_train)
    y_pred = lr.predict(X_test_std)
    print_stats_percentage_train_test(lr, y_test, y_pred)

def random_forest_rc(X_train_std, y_train, X_test_std, y_test):
    forest = RandomForestClassifier( )
   
    forest.fit(X_train_std, y_train)
    y_pred = forest.predict(X_test_std)
    print_stats_percentage_train_test(forest, y_test, y_pred)

def svm_rc(X_train_std, y_train, X_test_std, y_test):
    
    
    svm=SVC(probability=True)
    svm.fit(X_train_std, y_train)   
    y_pred = svm.predict(X_test_std)

def decision_trees_rc(X_train_std, y_train, X_test_std, y_test):
    tree = DecisionTreeClassifier(random_state=80)
    tree.fit(X_train_std, y_train)
    y_pred = tree.predict(X_test_std)
    print_stats_percentage_train_test(tree, y_test, y_pred)
   
def lda_rc(X_train_std, y_train, X_test_std, y_test):    
    lda = LinearDiscriminantAnalysis()
    lda.fit(X_train_std, y_train)
    y_pred = lda.predict(X_test_std)
    print_stats_percentage_train_test(lda, y_test, y_pred)
def gnb_rc(X_train_std, y_train, X_test_std, y_test):
    gnb = GaussianNB()
    gnb.fit(X_train_std, y_train)
    y_pred = gnb.predict(X_test_std)
    print_stats_percentage_train_test(gnb, y_test, y_pred)
    
from sklearn.ensemble import ExtraTreesRegressor
def extra_tree(X_train_std, y_train, X_test_std, y_test):
    extra = ExtraTreesClassifier()   
    extra.fit(X_train_std, y_train)
    y_pred = extra.predict(X_test_std)       
    print_stats_percentage_train_test(extra, y_test, y_pred)

def gradient_boosting(X_train_std, y_train, X_test_std, y_test):    
    gradient = GradientBoostingClassifier()
    gradient.fit(X_train_std, y_train)
    y_pred = gradient.predict(X_test_std)
    print_stats_percentage_train_test(gradient, y_test, y_pred)
def ada_boosting(X_train_std, y_train, X_test_std, y_test):
    ada = AdaBoostClassifier()
    ada.fit(X_train_std, y_train)
    y_pred = ada.predict(X_test_std)
    print_stats_percentage_train_test(ada, y_test, y_pred)
def xgboost(X_train_std, y_train, X_test_std, y_test):
    from xgboost import XGBClassifier
    xgb = XGBClassifier()    
    xgb.fit(X_train_std, y_train)   
    y_pred = xgb.predict(X_test_std)
    print_stats_percentage_train_test(xgb, y_test, y_pred)
    
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train_std = X_train
X_test_std = X_test

logistic_regression_rc(X_train_std, y_train, X_test_std, y_test)
knn_rc(X_train_std, y_train, X_test_std, y_test)
decision_trees_rc(X_train_std, y_train, X_test_std, y_test) 
gnb_rc(X_train_std, y_train, X_test_std, y_test)
lda_rc(X_train_std, y_train, X_test_std, y_test)
ada_boosting(X_train_std, y_train, X_test_std, y_test)
gradient_boosting(X_train_std, y_train, X_test_std, y_test)
extra_tree(X_train_std, y_train, X_test_std, y_test)
xgboost(X_train_std, y_train, X_test_std, y_test)
random_forest_rc(X_train_std, y_train, X_test_std, y_test)
svm_rc(X_train_std, y_train, X_test_std, y_test)